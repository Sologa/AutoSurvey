# LatteReview Wrapper å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### 1. å®‰è£…ä¾èµ–

```bash
cd AutoSurvey
pip install -r requirements_lattereview.txt
```

### 2. è®¾ç½®APIå¯†é’¥

```bash
# OpenAI API
export OPENAI_API_KEY="your-openai-api-key"

# æˆ–è€…åˆ›å»º .env æ–‡ä»¶
echo "OPENAI_API_KEY=your-openai-api-key" > .env
```

### 3. åˆ›å»ºç¬¬ä¸€ä¸ªè¯„å®¡

```python
from lattereview_wrapper import run_lattereview_evaluation_sync

# å®šä¹‰ç ”ç©¶ä¸»é¢˜
topic = "AI in Healthcare"

# é€‰æ‹©æ¨¡å‹
reviewer_models = ["gpt-4o-mini", "gpt-4.1-mini", "gpt-5-mini"]

# å‡†å¤‡è®ºæ–‡
papers = [
    {
        "id": "1",
        "title": "Deep Learning for Medical Diagnosis",
        "abstract": "We present a deep learning approach for automated medical diagnosis..."
    }
]

# è¿è¡Œè¯„å®¡
result = run_lattereview_evaluation_sync(
    topic=topic,
    reviewer_models=reviewer_models,
    papers=papers
)

print(f"è¯„å®¡å®Œæˆ! é«˜åˆ†è®ºæ–‡: {len(result['analysis']['high_score_papers'])} ç¯‡")
```

## ğŸ“‹ å®Œæ•´ç¤ºä¾‹

### åŸºæœ¬è¯„å®¡æµç¨‹

```python
from lattereview_wrapper import run_lattereview_evaluation_sync

def review_papers():
    # 1. å‡†å¤‡æ•°æ®
    topic = "Machine Learning Applications"
    reviewer_models = ["gpt-4o-mini", "gpt-4.1-mini", "gpt-5-mini"]
    
    papers = [
        {
            "id": "ml_001",
            "title": "Neural Networks for Image Recognition",
            "abstract": "This paper explores the use of neural networks..."
        },
        {
            "id": "ml_002", 
            "title": "Reinforcement Learning in Robotics",
            "abstract": "We investigate reinforcement learning approaches..."
        }
    ]
    
    # 2. è¿è¡Œè¯„å®¡
    result = run_lattereview_evaluation_sync(
        topic=topic,
        reviewer_models=reviewer_models,
        papers=papers,
        output_dir="./ml_review_results"
    )
    
    # 3. å¤„ç†ç»“æœ
    if result["success"]:
        print(f"âœ… è¯„å®¡æˆåŠŸ!")
        print(f"ğŸ“Š è®ºæ–‡æ•°é‡: {result['total_papers']}")
        print(f"ğŸ’° æ€»æˆæœ¬: ${result['total_cost']:.4f}")
        print(f"â±ï¸  è€—æ—¶: {result['duration_seconds']:.2f} ç§’")
        
        # æ˜¾ç¤ºé«˜åˆ†è®ºæ–‡
        high_score_papers = result['analysis']['high_score_papers']
        if high_score_papers:
            print(f"\nğŸ† é«˜åˆ†è®ºæ–‡ (â‰¥4åˆ†):")
            for paper in high_score_papers:
                print(f"  â€¢ {paper['title']} (æœ€é«˜åˆ†: {paper['max_score']})")
    else:
        print(f"âŒ è¯„å®¡å¤±è´¥: {result['error']}")

if __name__ == "__main__":
    review_papers()
```

### è‡ªå®šä¹‰è¯„å®¡æ ‡å‡†

```python
# å®šä¹‰ç‰¹å®šçš„çº³å…¥å’Œæ’é™¤æ ‡å‡†
inclusion_criteria = """
Research must demonstrate:
1. Novel methodology or significant improvement
2. Comprehensive evaluation with real data
3. Clear practical applications
4. Proper statistical analysis
"""

exclusion_criteria = """
Exclude research that:
1. Only presents theoretical concepts
2. Lacks experimental validation
3. Uses outdated techniques
4. Has insufficient sample sizes
"""

result = run_lattereview_evaluation_sync(
    topic="Computer Vision Research",
    reviewer_models=["gpt-4o-mini", "gpt-4.1-mini", "gpt-5-mini"],
    papers=papers,
    inclusion_criteria=inclusion_criteria,
    exclusion_criteria=exclusion_criteria
)
```

### æ‰¹é‡å¤„ç†å¤§é‡è®ºæ–‡

```python
import json

# ä»æ–‡ä»¶åŠ è½½è®ºæ–‡
with open("papers.json", "r") as f:
    papers = json.load(f)

print(f"åŠ è½½äº† {len(papers)} ç¯‡è®ºæ–‡")

# åˆ†æ‰¹å¤„ç†
batch_size = 50
for i in range(0, len(papers), batch_size):
    batch = papers[i:i+batch_size]
    print(f"\nå¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹ ({len(batch)} ç¯‡è®ºæ–‡)")
    
    result = run_lattereview_evaluation_sync(
        topic="AI Research Survey",
        reviewer_models=["gpt-4o-mini", "gpt-4.1-mini", "gpt-5-mini"],
        papers=batch,
        output_dir=f"./batch_results/batch_{i//batch_size + 1}"
    )
    
    if result["success"]:
        print(f"âœ… æ‰¹æ¬¡å®Œæˆ! æˆæœ¬: ${result['total_cost']:.4f}")
    else:
        print(f"âŒ æ‰¹æ¬¡å¤±è´¥: {result['error']}")
```

## ğŸ”§ å¸¸è§é…ç½®

### æ¨¡å‹é€‰æ‹©

```python
# OpenAI ç³»åˆ—
openai_models = ["gpt-4o-mini", "gpt-4.1-mini", "gpt-5-mini"]

# Claude ç³»åˆ—
claude_models = ["claude-3-sonnet", "claude-3-opus", "gpt-5-mini"]

# æ··åˆæ¨¡å‹
mixed_models = ["gpt-4o-mini", "claude-3-sonnet", "gpt-5-mini"]
```

### è¾“å‡ºç›®å½•ç»“æ„

```
output_dir/
â”œâ”€â”€ lattereview_results_AI_in_Healthcare.json  # è¯„å®¡ç»“æœ
â”œâ”€â”€ lattereview_analysis_AI_in_Healthcare.json # åˆ†ææŠ¥å‘Š
â””â”€â”€ summary.txt                                # æ‘˜è¦æŠ¥å‘Š
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIé™åˆ¶**: æ³¨æ„å„æ¨¡å‹çš„è°ƒç”¨é™åˆ¶
2. **æˆæœ¬æ§åˆ¶**: å¤§é‡è®ºæ–‡è¯„å®¡å¯èƒ½äº§ç”Ÿé«˜æˆæœ¬
3. **ç½‘ç»œç¨³å®šæ€§**: ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
4. **æ¨¡å‹å¯ç”¨æ€§**: éªŒè¯æ¨¡å‹åœ¨æ‚¨çš„è´¦æˆ·ä¸­å¯ç”¨

## ğŸ†˜ æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯

```python
# 1. APIå¯†é’¥é”™è¯¯
# é”™è¯¯: "OPENAI_API_KEY environment variable is not set"
# è§£å†³: è®¾ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡

# 2. æ¨¡å‹ä¸å¯ç”¨
# é”™è¯¯: "Model not found"
# è§£å†³: æ£€æŸ¥æ¨¡å‹åç§°å’Œè´¦æˆ·æƒé™

# 3. ç½‘ç»œé”™è¯¯
# é”™è¯¯: "Connection timeout"
# è§£å†³: æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®
```

### è°ƒè¯•æ¨¡å¼

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# è¿è¡Œè¯„å®¡æ—¶ä¼šæ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
result = run_lattereview_evaluation_sync(...)
```

## ğŸ“š ä¸‹ä¸€æ­¥

- æŸ¥çœ‹å®Œæ•´æ–‡æ¡£: `README_LatteReview_Wrapper.md`
- è¿è¡Œç¤ºä¾‹: `python example_lattereview_usage.py`
- è¿è¡Œæµ‹è¯•: `python test_lattereview_wrapper.py`

## ğŸ’¡ æç¤º

- ä»å°æ‰¹é‡å¼€å§‹æµ‹è¯•
- ç›‘æ§APIè°ƒç”¨æˆæœ¬
- ä¿å­˜é‡è¦çš„è¯„å®¡ç»“æœ
- æ ¹æ®åé¦ˆè°ƒæ•´è¯„å®¡æ ‡å‡†

---

**éœ€è¦å¸®åŠ©?** æŸ¥çœ‹å®Œæ•´æ–‡æ¡£æˆ–è¿è¡Œæµ‹è¯•è„šæœ¬ï¼
