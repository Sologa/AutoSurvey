#!/usr/bin/env python3
"""
ä½¿ç”¨æœ€ç»ˆåˆ†æ•°è®¡ç®—çš„LatteReviewç¤ºä¾‹
å±•ç¤ºå¦‚ä½•è·å–æŒ‰æœ€ç»ˆåˆ†æ•°æ’åºçš„å‰Nç¯‡è®ºæ–‡
"""

from lattereview_wrapper import run_lattereview_evaluation_sync


def example_with_final_score():
    """ä½¿ç”¨æœ€ç»ˆåˆ†æ•°è®¡ç®—çš„ç¤ºä¾‹"""
    print("=== ä½¿ç”¨æœ€ç»ˆåˆ†æ•°è®¡ç®—çš„ç¤ºä¾‹ ===")
    
    # å®šä¹‰ç ”ç©¶ä¸»é¢˜
    topic = "Large Language Models in Academic Research"
    
    # å®šä¹‰ä¸‰ä¸ªè¯„å®¡è€…æ¨¡å‹
    reviewer_models = [
        "gpt-4o-mini",      # Conservative Reviewer (Junior)
        "gpt-4.1-mini",     # Balanced Reviewer (Junior)
        "gpt-5-mini"        # Senior Reviewer
    ]
    
    # å®šä¹‰è¦è¯„å®¡çš„è®ºæ–‡
    papers = [
        {
            "id": "paper_001",
            "title": "Large Language Models for Automated Literature Review",
            "abstract": "This paper presents a novel approach to using large language models for automated literature review processes. We demonstrate how GPT-based models can effectively analyze academic papers and generate comprehensive summaries."
        },
        {
            "id": "paper_002", 
            "title": "AI-Assisted Research: A Survey of Current Applications",
            "abstract": "We survey the current state of AI-assisted research tools and methodologies. Our analysis covers various domains including natural language processing, computer vision, and scientific discovery."
        },
        {
            "id": "paper_003",
            "title": "Automated Survey Generation Using Transformer Models",
            "abstract": "This work explores the use of transformer-based models for automatically generating comprehensive literature surveys. We evaluate the quality and accuracy of generated surveys compared to human-written ones."
        },
        {
            "id": "paper_004",
            "title": "Machine Learning in Scientific Discovery",
            "abstract": "This paper discusses the application of machine learning techniques in scientific discovery processes, including drug discovery, materials science, and climate modeling."
        },
        {
            "id": "paper_005",
            "title": "Deep Learning for Research Automation",
            "abstract": "We present a comprehensive framework for automating research processes using deep learning techniques, including literature analysis, hypothesis generation, and experimental design."
        }
    ]
    
    print(f"ä¸»é¢˜: {topic}")
    print(f"è¯„å®¡æ¨¡å‹: {reviewer_models}")
    print(f"è®ºæ–‡æ•°é‡: {len(papers)}")
    
    # è¿è¡Œè¯„å®¡ï¼Œè·å–å‰3ç¯‡è®ºæ–‡
    print("\nå¼€å§‹è¯„å®¡ï¼Œè¾“å‡ºå‰3ç¯‡è®ºæ–‡...")
    result = run_lattereview_evaluation_sync(
        topic=topic,
        reviewer_models=reviewer_models,
        papers=papers,
        top_n=3,  # æŒ‡å®šè¾“å‡ºå‰3ç¯‡è®ºæ–‡
        output_dir="./final_score_example_output"
    )
    
    # å¤„ç†ç»“æœ
    if result["success"]:
        print(f"\nâœ… è¯„å®¡æˆåŠŸå®Œæˆ!")
        print(f"ä¸»é¢˜: {result['topic']}")
        print(f"è®ºæ–‡æ•°é‡: {result['total_papers']}")
        print(f"è€—æ—¶: {result['duration_seconds']:.2f} ç§’")
        print(f"æ€»æˆæœ¬: ${result['total_cost']:.4f}")
        
        # æ˜¾ç¤ºå‰3ç¯‡è®ºæ–‡ï¼ˆæŒ‰æœ€ç»ˆåˆ†æ•°æ’åºï¼‰
        top_papers = result['analysis']['top_papers']
        print(f"\nğŸ† å‰3ç¯‡è®ºæ–‡ (æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº):")
        for i, paper in enumerate(top_papers):
            print(f"  {i+1}. {paper['title']}")
            print(f"     æœ€ç»ˆåˆ†æ•°: {paper['final_score']:.2f}")
            print(f"     æ‰€æœ‰åˆ†æ•°: {paper['all_scores']}")
            print(f"     åˆ†æ•°è¯¦æƒ…: {paper['score_details']}")
            print()
        
        # æ˜¾ç¤ºé«˜åˆ†è®ºæ–‡ç»Ÿè®¡
        high_score_papers = result['analysis']['high_score_papers']
        print(f"ğŸ“Š é«˜åˆ†è®ºæ–‡ç»Ÿè®¡ (â‰¥4åˆ†): {len(high_score_papers)} ç¯‡")
        
        # æ˜¾ç¤ºè¯„å®¡è½®æ¬¡ä¿¡æ¯
        review_rounds = result['analysis']['review_rounds']
        print(f"\nğŸ“‹ è¯„å®¡è½®æ¬¡ä¿¡æ¯:")
        for round_info in review_rounds:
            print(f"  è½®æ¬¡ {round_info['round']}:")
            for reviewer in round_info['reviewers']:
                print(f"    {reviewer['name']}: è¯„å®¡ {reviewer['total_reviews']} ç¯‡")
                if reviewer['mean_evaluation']:
                    print(f"      å¹³å‡åˆ†: {reviewer['mean_evaluation']:.2f}")
        
    else:
        print(f"\nâŒ è¯„å®¡å¤±è´¥: {result['error']}")


def example_compare_different_top_n():
    """æ¯”è¾ƒä¸åŒtop_nå‚æ•°çš„æ•ˆæœ"""
    print("\n=== æ¯”è¾ƒä¸åŒtop_nå‚æ•°çš„æ•ˆæœ ===")
    
    topic = "Computer Vision Research"
    reviewer_models = ["gpt-4o-mini", "gpt-4.1-mini", "gpt-5-mini"]
    
    papers = [
        {
            "id": "cv_001",
            "title": "Deep Learning for Object Detection",
            "abstract": "We present a novel deep learning approach for object detection in computer vision applications."
        },
        {
            "id": "cv_002",
            "title": "Image Segmentation Using CNNs",
            "abstract": "This paper explores convolutional neural networks for image segmentation tasks."
        },
        {
            "id": "cv_003",
            "title": "Computer Vision in Autonomous Vehicles",
            "abstract": "We investigate computer vision techniques for autonomous vehicle navigation."
        },
        {
            "id": "cv_004",
            "title": "Medical Image Analysis with AI",
            "abstract": "This work presents AI-based methods for medical image analysis and diagnosis."
        },
        {
            "id": "cv_005",
            "title": "Real-time Video Processing",
            "abstract": "We develop real-time video processing algorithms for surveillance applications."
        }
    ]
    
    # æµ‹è¯•ä¸åŒçš„top_nå€¼
    for top_n in [2, 3, 5]:
        print(f"\n--- è¾“å‡ºå‰ {top_n} ç¯‡è®ºæ–‡ ---")
        
        result = run_lattereview_evaluation_sync(
            topic=topic,
            reviewer_models=reviewer_models,
            papers=papers,
            top_n=top_n,
            output_dir=f"./top_n_comparison/top_{top_n}"
        )
        
        if result["success"]:
            top_papers = result['analysis']['top_papers']
            print(f"æˆåŠŸè·å–å‰ {len(top_papers)} ç¯‡è®ºæ–‡:")
            
            for i, paper in enumerate(top_papers):
                print(f"  {i+1}. {paper['title']} (åˆ†æ•°: {paper['final_score']:.2f})")
        else:
            print(f"å¤±è´¥: {result['error']}")


def explain_final_score_algorithm():
    """è§£é‡Šæœ€ç»ˆåˆ†æ•°è®¡ç®—ç®—æ³•"""
    print("\n=== æœ€ç»ˆåˆ†æ•°è®¡ç®—ç®—æ³•è¯´æ˜ ===")
    
    print("""
æœ€ç»ˆåˆ†æ•° S_final çš„è®¡ç®—è§„åˆ™ï¼š

1. ä¼˜å…ˆä½¿ç”¨ round-B_Senior_Reviewer_evaluation
   - è¿™æ˜¯Seniorè¯„å®¡è€…åœ¨Round Bä¸­çš„è¯„åˆ†
   - åªæœ‰å½“ä¸¤ä¸ªJuniorè¯„å®¡è€…åˆ†æ­§â‰¥2åˆ†æ—¶æ‰ä¼šäº§ç”Ÿ

2. å…¶æ¬¡ä½¿ç”¨ round-A_Senior_Reviewer_evaluation  
   - è¿™æ˜¯Seniorè¯„å®¡è€…åœ¨Round Aä¸­çš„è¯„åˆ†
   - å¦‚æœSeniorè¯„å®¡è€…å‚ä¸äº†Round A

3. æœ€åå–ä¸¤ä½Juniorè¯„å®¡è€…çš„å¹³å‡åˆ†
   - Conservative_Reviewer_evaluation
   - Balanced_Reviewer_evaluation
   - è®¡ç®—: (conservative + balanced) / 2

4. å¦‚æœåªæœ‰ä¸€ä¸ªJuniorçš„åˆ†æ•°ï¼Œç›´æ¥ä½¿ç”¨è¯¥åˆ†æ•°

è¯„å®¡æµç¨‹ï¼š
- Round A: Conservative + Balanced è¯„å®¡æ‰€æœ‰è®ºæ–‡
- Round B: åªæœ‰å½“ä¸¤ä¸ªJuniorè¯„åˆ†å·®å¼‚â‰¥2åˆ†æ—¶ï¼ŒSenioræ‰è¯„å®¡
- è¿™æ ·å¯ä»¥èŠ‚çœæˆæœ¬ï¼Œåªå¯¹åˆ†æ­§è¾ƒå¤§çš„è®ºæ–‡è¿›è¡ŒSeniorè¯„å®¡
    """)


if __name__ == "__main__":
    print("æœ€ç»ˆåˆ†æ•°è®¡ç®—ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        # è§£é‡Šç®—æ³•
        explain_final_score_algorithm()
        
        # è¿è¡ŒåŸºæœ¬ç¤ºä¾‹
        example_with_final_score()
        
        # æ¯”è¾ƒä¸åŒtop_nå‚æ•°
        example_compare_different_top_n()
        
        print("\n" + "=" * 50)
        print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        
    except Exception as e:
        print(f"è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
